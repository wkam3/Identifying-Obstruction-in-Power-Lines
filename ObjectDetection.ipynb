{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.66  Python-3.12.7 torch-2.5.1+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "Setup complete  (16 CPUs, 31.7 GB RAM, 397.7/933.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import roboflow\n",
    "\n",
    "roboflow.login()\n",
    "\n",
    "rf = roboflow.Roboflow()\n",
    "\n",
    "project = rf.workspace(\"powerlineobstructiondetection\").project(\"test-kpzbb\")\n",
    "dataset = project.version(3).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = YOLO('/Users/bsath/Identifying-Obstruction-in-Power-Lines/YOLOv8/yolov8n')\n",
    "\n",
    "model.train(\n",
    "    data='/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=416,\n",
    "    batch=4,\n",
    "    device = 'cpu',\n",
    "    resume=True,\n",
    "    amp=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged into Roboflow. To make a different login,run roboflow.login(force=True).\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "import roboflow\n",
    "\n",
    "roboflow.login()\n",
    "\n",
    "rf = roboflow.Roboflow()\n",
    "\n",
    "project = rf.workspace(\"powerlineobstructiondetection\").project(\"test-kpzbb\")\n",
    "model = project.version(3).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics = model.val(data='/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/data.yaml', device='cpu')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'x': 467.5, 'y': 320.0, 'width': 343.0, 'height': 634.0, 'confidence': 0.854458749294281, 'class': 'wires', 'class_id': 2, 'detection_id': '1da40908-6830-4723-9929-4103bfa2dea6', 'image_path': '/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/test/images/4dfec6c47f43a61dff52_jpg.rf.30a932e904c1733f0f6aeb79659bde2c.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 263.0, 'y': 460.0, 'width': 84.0, 'height': 356.0, 'confidence': 0.809465765953064, 'class': 'wires', 'class_id': 2, 'detection_id': 'b5e9f397-99d2-47d1-bac8-326ec244c654', 'image_path': '/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/test/images/4dfec6c47f43a61dff52_jpg.rf.30a932e904c1733f0f6aeb79659bde2c.jpg', 'prediction_type': 'ObjectDetectionModel'}], 'image': {'width': '640', 'height': '640'}}\n"
     ]
    }
   ],
   "source": [
    "result = model.predict('/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/test/images/4dfec6c47f43a61dff52_jpg.rf.30a932e904c1733f0f6aeb79659bde2c.jpg')\n",
    "predictions = result.json()\n",
    "print(result.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('/Users/bsath/Identifying-Obstruction-in-Power-Lines/Test-3/test/images/4dfec6c47f43a61dff52_jpg.rf.30a932e904c1733f0f6aeb79659bde2c.jpg')\n",
    "image = cv2.resize(image, (640, 640))\n",
    "predictions = result.json()  # Get predictions\n",
    "\n",
    "for prediction in predictions['predictions']:\n",
    "    x1 = int(prediction['x'])\n",
    "    y1 = int(prediction['y'])\n",
    "    width = int(prediction['width'])\n",
    "    height = int(prediction['height'])\n",
    "    \n",
    "    # Calculate the bottom-right corner of the bounding box\n",
    "    x2 = x1 + width\n",
    "    y2 = y1 + height\n",
    "    \n",
    "    # Draw the rectangle on the image (BGR format for OpenCV)\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box\n",
    "    \n",
    "    # Add text label (class and confidence)\n",
    "    label = prediction['class']\n",
    "    confidence = prediction['confidence']\n",
    "    cv2.putText(image, f\"{label} ({confidence*100:.1f}%)\", \n",
    "                (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "print(image_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Convert to PIL Image for display\n",
    "image_pil = Image.fromarray(image_rgb)\n",
    "\n",
    "# Display the image\n",
    "image_pil.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
